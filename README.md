![image](https://github.com/user-attachments/assets/8d895b04-8747-4d39-9e08-75361af603d8)## EDITH (EVEN DEAF, I'M THE HERO)

## Aim
To develop an efficient model of a Sign Language interpreter exclusive for Indian Sign Language(ISL) 

## Abstract

Sign language is a visual language that utilizes hand shapes, movements, facial expressions, and body postures to communicate meaning. Unlike spoken languages, it communicates through gestures and non-manual signals like eye gaze and body posture. Different regions have unique sign languages, such as **ASL**, **BSL**, and **ISL**, each with distinct grammar. Advances in technology, like gesture recognition and AI, aim to improve communication between signers and non-signers, fostering inclusivity.

## Project Description

Indian Sign Language (ISL) is the primary form of communication for many Deaf and hard-of-hearing individuals in India. It is a visual-gestural language that uses hand signs, facial expressions, and body movements to convey meaning, much like other sign languages worldwide. However, ISL is unique compared to Western counterparts like American Sign Language (ASL) and British Sign Language (BSL) because it incorporates signs from Indian languages such as Hindi, Tamil, and others. ISL has often been under-recognized and under-documented compared to Western sign languages.

ISL has its own grammar, syntax, and sentence structure like other sign languages. The word order in ISL typically differs from that of spoken Indian languages, and it relies heavily on non-manual signals like facial expressions to convey tone, questions, or emphasis. Many ISL signs are deeply connected to Indian cultural contexts. Given Indiaâ€™s diversity, there are regional variations, but mutual intelligibility is generally maintained across the country.

There remains a shortage of trained ISL interpreters in India, which creates challenges for deaf individuals in healthcare, legal settings, and general communication.

To address this gap, our model, EDITH, aims to function as a bridge, filling the need for professionally trained ISL interpreters.

Communication is the exchange of thoughts and messages through various means such as speech, signals, behavior, and visuals. Deaf and Mute (D&M) individuals use their hands to express gestures. EDITH serves as an interpreter between D&M individuals and others, helping the latter understand the signs made by the former.

## Pre-Requisites
Python
React.js
OpenCV
Basic knowledge of Machine Learning

## Methology

### Data collection
    Here, the dataset is defined by the programmer. This specifically uses OpenCV to collect the datasets for the signs of words.
### Data processing
    Here, The collected dataset is processed thoroughly  
training
testing
webpage development

## Features

This prototype is special for indian sign language as we believe this is the first dedicated model which can interpret in both ways, ie from *Sign* to *Word* and *Speech* and *Word* to *A Sign video*. This builds the bridge between Deaf & Mute People and Ordinary People.
This model also shines bright as a learning and teaching tool for Indian Sign Language.




